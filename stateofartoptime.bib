@article {Forrester3251,
	author = {Forrester, Alexander I.J and S{\'o}bester, Andr{\'a}s and Keane, Andy J},
	title = {Multi-fidelity optimization via surrogate modelling},
	volume = {463},
	number = {2088},
	pages = {3251--3269},
	year = {2007},
	doi = {10.1098/rspa.2007.1900},
	publisher = {The Royal Society},
	abstract = {This paper demonstrates the application of correlated Gaussian process based approximations to optimization where multiple levels of analysis are available, using an extension to the geostatistical method of co-kriging. An exchange algorithm is used to choose which points of the search space to sample within each level of analysis. The derivation of the co-kriging equations is presented in an intuitive manner, along with a new variance estimator to account for varying degrees of computational {\textquoteleft}noise{\textquoteright} in the multiple levels of analysis. A multi-fidelity wing optimization is used to demonstrate the methodology.},
	issn = {1364-5021},
	URL = {http://rspa.royalsocietypublishing.org/content/463/2088/3251},
	eprint = {http://rspa.royalsocietypublishing.org/content/463/2088/3251.full.pdf},
	journal = {Proceedings of the Royal Society of London A: Mathematical, Physical and Engineering Sciences}
}

@article{Xian2018,
  author={Xiangnan Zhang},
  title={Review of Reliability-Based Design Optimization Approach and Its Integration with Bayesian Method},
  journal={IOP Conference Series: Earth and Environmental Science},
  volume={128},
  number={1},
  pages={012109},
  url={http://stacks.iop.org/1755-1315/128/i=1/a=012109},
  year={2018},
  abstract={A lot of uncertain factors lie in practical engineering, such as external load environment, material property, geometrical shape, initial condition, boundary condition, etc. Reliability method measures the structural safety condition and determine the optimal design parameter combination based on the probabilistic theory. Reliability-based design optimization (RBDO) is the most commonly used approach to minimize the structural cost or other performance under uncertainty variables which combines the reliability theory and optimization. However, it cannot handle the various incomplete information. The Bayesian approach is utilized to incorporate this kind of incomplete information in its uncertainty quantification. In this paper, the RBDO approach and its integration with Bayesian method are introduced.}
}

@InProceedings{Gins2015,
author="Marmin, S{\'e}bastien
and Chevalier, Cl{\'e}ment
and Ginsbourger, David",
editor="Pardalos, Panos
and Pavone, Mario
and Farinella, Giovanni Maria
and Cutello, Vincenzo",
title="Differentiating the Multipoint Expected Improvement for Optimal Batch Design",
booktitle="Machine Learning, Optimization, and Big Data",
year="2015",
publisher="Springer International Publishing",
address="Cham",
pages="37--48",
abstract="This work deals with parallel optimization of expensive objective functions which are modelled as sample realizations of Gaussian processes. The study is formalized as a Bayesian optimization problem, or continuous multi-armed bandit problem, where a batch of {\$}{\$}q > 0{\$}{\$}arms is pulled in parallel at each iteration. Several algorithms have been developed for choosing batches by trading off exploitation and exploration. As of today, the maximum Expected Improvement (EI) and Upper Confidence Bound (UCB) selection rules appear as the most prominent approaches for batch selection. Here, we build upon recent work on the multipoint Expected Improvement criterion, for which an analytic expansion relying on Tallis' formula was recently established. The computational burden of this selection rule being still an issue in application, we derive a closed-form expression for the gradient of the multipoint Expected Improvement, which aims at facilitating its maximization using gradient-based ascent algorithms. Substantial computational savings are shown in application. In addition, our algorithms are tested numerically and compared to state-of-the-art UCB-based batch-sequential algorithms. Combining starting designs relying on UCB with gradient-based EI local optimization finally appears as a sound option for batch design in distributed Gaussian Process optimization.",
isbn="978-3-319-27926-8"
}

@Article{Cressie1990,
author="Cressie, Noel",
title="The origins of kriging",
journal="Mathematical Geology",
year="1990",
month="Apr",
day="01",
volume="22",
number="3",
pages="239--252",
abstract="In this article, kriging is equated with spatial optimal linear prediction, where the unknown random-process mean is estimated with the best linear unbiased estimator. This allows early appearances of (spatial) prediction techniques to be assessed in terms of how close they came to kriging.",
issn="1573-8868",
doi="10.1007/BF00889887",
url="https://doi.org/10.1007/BF00889887"
}

@Article{Auger2012,
  author   = {Anne Auger and Johannes Bader and Dimo Brockhoff and Eckart Zitzler},
  title    = {Hypervolume-based multiobjective optimization: Theoretical foundations and practical implications},
  journal  = {Theoretical Computer Science},
  year     = {2012},
  volume   = {425},
  pages    = {75 - 103},
  issn     = {0304-3975},
  note     = {Theoretical Foundations of Evolutionary Computation},
  doi      = {https://doi.org/10.1016/j.tcs.2011.03.012},
  keywords = {Multiobjective optimization, Evolutionary algorithms, Hypervolume indicator, Reference point, Optimal -distributions},
  url      = {http://www.sciencedirect.com/science/article/pii/S0304397511002428}
}

@Article{Deb2002,
  author   = {K. Deb and A. Pratap and S. Agarwal and T. Meyarivan},
  title    = {A fast and elitist multiobjective genetic algorithm: NSGA-II},
  journal  = {IEEE Transactions on Evolutionary Computation},
  year     = {2002},
  volume   = {6},
  number   = {2},
  pages    = {182-197},
  month    = {April},
  issn     = {1089-778X},
  doi      = {10.1109/4235.996017},
  keywords = {genetic algorithms;operations research;computational complexity;Pareto distribution;simulation;convergence;constraint theory;sorting;fast elitist multi-objective genetic algorithm;NSGA-II;Nondominated Sorting Genetic Algorithm II;multi-objective evolutionary algorithm;nondominated sharing;computational complexity;objectives;population size;selection operator;mating pool;parent/offspring population combination;solution fitness;solution spread;simulation;convergence;Pareto-optimal front;Pareto-archived evolution strategy;strength-Pareto evolutionary algorithm;dominance definition;constrained multi-objective problems;nonlinear problem;multi-objective optimization;algorithm performance;constraint handling;multi-criterion decision making;Genetic algorithms;Sorting;Computational complexity;Evolutionary computation;Computational modeling;Testing;Decision making;Associate members;Diversity reception;Constraint optimization}
}

@Article{Deb2014,
  author   = {K. Deb and H. Jain},
  title    = {An Evolutionary Many-Objective Optimization Algorithm Using Reference-Point-Based Nondominated Sorting Approach, Part I: Solving Problems With Box Constraints},
  journal  = {IEEE Transactions on Evolutionary Computation},
  year     = {2014},
  volume   = {18},
  number   = {4},
  pages    = {577-601},
  month    = {Aug},
  issn     = {1089-778X},
  doi      = {10.1109/TEVC.2013.2281535},
  keywords = {genetic algorithms;sorting;evolutionary many-objective optimization algorithm;reference-point-based nondominated sorting approach;box constraints;evolutionary multiobjective optimization algorithms;EMO algorithms;many-objective optimization problems;reference-point-based many-objective evolutionary algorithm;NSGA-II framework;reference points;many-objective test problems;MOEA/D methods;unconstrained problems;NSGA-III;Sociology;Statistics;Optimization;Vectors;Measurement;Zirconium;Educational institutions;Many-objective optimization;evolutionary computation;large dimension;NSGA-III;non-dominated sorting;multi-criterion optimization;Evolutionary computation;large dimension;many-objective optimization;multicriterion optimization;nondominated sorting;NSGA-III}
}

@InProceedings{Ishibuchi2016,
  author    = {H. Ishibuchi and R. Imada and Y. Setoguchi and Y. Nojima},
  title     = {Performance comparison of NSGA-II and NSGA-III on various many-objective test problems},
  booktitle = {2016 IEEE Congress on Evolutionary Computation (CEC)},
  year      = {2016},
  pages     = {3045-3052},
  month     = {July},
  doi       = {10.1109/CEC.2016.7744174},
  keywords  = {genetic algorithms;knapsack problems;minimisation;NSGA-III;many-objective test problems;evolutionary many-objective optimization;DTLZ test problems;WFG test problems;DTLZ1-4 problems;distance minimization problems;knapsack problems;NSGA-II;Minimization;Algorithm design and analysis;Correlation;Classification algorithms;Performance evaluation;Pareto optimization;Evolutionary multiobjective optimization (EMO);evolutionary many-objective optimization;many-objective problems;NSGA-II;NSGA-III}
}

@InProceedings{Auger2017,
  author    = {D. Brockhoff, A. Auger, N. Hansen and T. Tusar},
  title     = {Quantitative Performance Assessment of Multiobjective Optimizers: The Average Runtime Attainment Function},
  booktitle = {Evolutionary Multi-Criterion Optimization conference (EMO 2017)},
  year      = {2017},
  pages     = {103-119}
}

@Article{Palar2018,
  author   = {Palar, Pramudita Satria and Shimoyama, Koji},
  title    = {On efficient global optimization via universal Kriging surrogate models},
  journal  = {Structural and Multidisciplinary Optimization},
  year     = {2018},
  volume   = {57},
  number   = {6},
  pages    = {2377--2397},
  month    = {Jun},
  issn     = {1615-1488},
  abstract = {In this paper, we investigate the capability of the universal Kriging (UK) model for single-objective global optimization applied within an efficient global optimization (EGO) framework. We implemented this combined UK-EGO framework and studied four variants of the UK methods, that is, a UK with a first-order polynomial, a UK with a second-order polynomial, a blind Kriging (BK) implementation from the ooDACE toolbox, and a polynomial-chaos Kriging (PCK) implementation. The UK-EGO framework with automatic trend function selection derived from the BK and PCK models works by building a UK surrogate model and then performing optimizations via expected improvement criteria on the Kriging model with the lowest leave-one-out cross-validation error. Next, we studied and compared the UK-EGO variants and standard EGO using five synthetic test functions and one aerodynamic problem. Our results show that the proper choice for the trend function through automatic feature selection can improve the optimization performance of UK-EGO relative to EGO. From our results, we found that PCK-EGO was the best variant, as it had more robust performance as compared to the rest of the UK-EGO schemes; however, total-order expansion should be used to generate the candidate trend function set for high-dimensional problems. Note that, for some test functions, the UK with predetermined polynomial trend functions performed better than that of BK and PCK, indicating that the use of automatic trend function selection does not always lead to the best quality solutions. We also found that although some variants of UK are not as globally accurate as the ordinary Kriging (OK), they can still identify better-optimized solutions due to the addition of the trend function, which helps the optimizer locate the global optimum.},
  day      = {01},
  doi      = {10.1007/s00158-017-1867-1},
  url      = {https://doi.org/10.1007/s00158-017-1867-1}
}

@Article{Jones1998,
  author   = {Jones, Donald R. and Schonlau, Matthias and Welch, William J.},
  title    = {Efficient Global Optimization of Expensive Black-Box Functions},
  journal  = {Journal of Global Optimization},
  year     = {1998},
  volume   = {13},
  number   = {4},
  pages    = {455--492},
  month    = {Dec},
  issn     = {1573-2916},
  abstract = {In many engineering optimization problems, the number of function evaluations is severely limited by time or cost. These problems pose a special challenge to the field of global optimization, since existing methods often require more function evaluations than can be comfortably afforded. One way to address this challenge is to fit response surfaces to data collected by evaluating the objective and constraint functions at a few points. These surfaces can then be used for visualization, tradeoff analysis, and optimization. In this paper, we introduce the reader to a response surface methodology that is especially good at modeling the nonlinear, multimodal functions that often occur in engineering. We then show how these approximating functions can be used to construct an efficient global optimization algorithm with a credible stopping rule. The key to using response surfaces for global optimization lies in balancing the need to exploit the approximating surface (by sampling where it is minimized) with the need to improve the approximation (by sampling where prediction error may be high). Striking this balance requires solving certain auxiliary problems which have previously been considered intractable, but we show how these computational obstacles can be overcome.},
  day      = {01},
  doi      = {10.1023/A:1008306431147},
  url      = {https://doi.org/10.1023/A:1008306431147}
}
